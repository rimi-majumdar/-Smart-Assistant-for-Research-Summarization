# ğŸ§  Smart Assistant for Research Summarization

## ğŸ“Œ Objective

This project aims to simulate a document-aware **AI assistant** that can:
- Answer comprehension and inference-based questions from user-uploaded documents.
- Generate logic-based questions and evaluate user responses.
- Justify every answer with a direct reference from the document.

---

## ğŸ§© Problem Statement

Traditional tools fail to deeply understand complex documents like research papers or technical manuals. This assistant is designed to go beyond keyword searches and provide **contextual understanding**, **reasoning**, and **justified responses**.

The assistant can:
- Read and understand long PDF/TXT documents.
- Support free-form Q&A and logic-based questions.
- Provide contextual references from the uploaded content.

---

## ğŸš€ Features

### âœ… 1. Document Upload
- Supports `.pdf` and `.txt` formats.
- Accepts structured English documents such as reports and research papers.

### âœ… 2. Interaction Modes

#### ğŸ”¹ a. Ask Anything
- Users can ask **free-form questions** based on the uploaded document.
- The assistant answers with **contextual understanding** and direct references.

#### ğŸ”¹ b. Challenge Me
- Automatically generates **3 logic/comprehension-based questions**.
- Users attempt to answer them.
- The assistant evaluates the responses and provides **feedback with justification**.

### âœ… 3. Contextual Understanding
- All responses are **grounded in actual document content**.
- Each answer includes a snippet reference, e.g., â€œ*Paragraph 3 of Section 1*â€.
- Avoids hallucinations or fabrications.

### âœ… 4. Auto Summary
- Instantly generates a **â‰¤150-word summary** of the uploaded document.

### âœ… 5. Application Architecture
- **Frontend**: Built using [Streamlit](https://streamlit.io/) for a simple, interactive web interface.
- **Backend**: Powered by Python (Flask-based logic modules).

---

## ğŸŒŸ Bonus Features (Implemented)

- âœ… **Memory Handling**: Handles follow-up questions using prior context.
- âœ… **Answer Highlighting**: Highlights **document snippets** that justify each answer.

---

## ğŸ—ï¸ Architecture / Reasoning Flow

```mermaid
graph TD
    A[User Uploads PDF/TXT] --> B[Document Preprocessing & Summarization]
    B --> C{Choose Mode}
    C --> D[Ask Anything: User types a question]
    C --> E[Challenge Me: System generates logic-based questions]
    D --> F[LLM processes user question + context]
    E --> G[LLM generates 3 questions]
    G --> H[User submits answers]
    H --> I[Assistant evaluates and gives feedback with justification]
    F --> J[Answer with snippet + justification]



## ğŸ— Setup Instructions

1. Clone the repo:

bash
git clone https://github.com/rimi-majumdar/-Smart-Assistant-for-Research-Summarization.git
cd -Smart-Assistant-for-Research-Summarization


2. Install dependencies:

bash
pip install -r requirements.txt


3. Run the app locally:

bash
streamlit run main.py --server.port 10000 --server.address 0.0.0.0


---

## ğŸš€ Deployment on Render

1. Push this repo to GitHub
2. Go to [https://render.com](https://render.com)
3. Click "New â†’ Web Service"
4. Use:

   * Build Command: pip install -r requirements.txt
   * Start Command: streamlit run main.py --server.port 10000 --server.address 0.0.0.0
5. Wait for deployment and open your URL

---


ğŸ“‚ Folder Structure
bash
Copy
Edit
Smart-Assistant-for-Research-Summarization/
â”‚
â”œâ”€â”€ app.py                    # Streamlit main entry point
â”œâ”€â”€ backend/                  # Core logic
â”‚   â”œâ”€â”€ qa_engine.py          # Handles Q&A and challenge logic
â”‚   â”œâ”€â”€ summarizer.py         # Summarization module
â”‚   â””â”€â”€ memory_handler.py     # Memory support for follow-ups
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ pdf_reader.py         # Extract text from PDF/TXT
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ“½ï¸ Demo
ğŸ¥ Click here to watch the demo
(Add link when available)

ğŸ™Œ Author
Rimi Majumdar
ğŸ”— GitHub Profile


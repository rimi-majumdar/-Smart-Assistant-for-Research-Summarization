# Smart Assistant for Research Summarization 

An intelligent research assistant that helps researchers upload papers, get concise summaries, ask context-aware questions, and even test their understanding through custom-generated challenges.

ğŸ”— Live App: [https://smart-assistant-for-research.onrender.com](https://smart-assistant-for-research.onrender.com)

---

## ğŸ§  Features

* ğŸ“„ Upload PDF or TXT research papers
* âœ¨ Automatic summary generation (max 150 words)
* ğŸ’¬ Ask Anything mode:

  * Ask natural questions grounded in uploaded content
  * Uses semantic search + OpenAI to find answers

* ğŸ¯ Challenge Me mode:

  * Automatically generates custom MCQs or open-ended questions
  * Evaluates and explains correctness of user answers

* ğŸ§µ Memory Handling (Bonus):

 
  * Follow-up questions are answered using full conversational history

* ğŸ” Answer Highlighting (Bonus):

  * Displays supporting document snippet for each answer

* âš¡ Streamlit UI with 2-mode toggle (Ask/Challenge)
* ğŸš€ Deployable on Render

---

## ğŸ§± Architecture Overview

1. ğŸ“‚ Upload Document (PDF or TXT) via Streamlit
2. ğŸ“ƒ Document text is extracted using PyPDF2 and cleaned
3. ğŸ§  Summary is generated via backend/summarizer.py
4. ğŸ’¬ In "Ask Anything" mode:

   * Question is routed to backend/qna\_engine.py
   * Uses embedding search + history-aware prompt to answer

5. ğŸ“ In "Challenge Me" mode:

   * Uses backend/challenge\_generator.py to make  questions
   * Evaluates user response and returns feedback



---

## ğŸ“ Directory Structure

```
Smart-Assistant-for-Research-Summarization/
ğŸ”¼ backend/
ğŸ”¼ summarizer.py
ğŸ”¼ qna_engine.py
ğŸ”¼ challenge_generator.py
ğŸ”¼ memory.py
ğŸ”¼ memory.json
ğŸ”¼ main.py
ğŸ”¼ requirements.txt
ğŸ”¼ .streamlit/
ğŸ”¼ config.toml
ğŸ”¼ README.md
```

---

## ğŸ—ï¸ Setup Instructions

1. Clone the repo:

```bash
git clone https://github.com/rimi-majumdar/-Smart-Assistant-for-Research-Summarization.git
cd -Smart-Assistant-for-Research-Summarization
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Run the app locally:

```bash
streamlit run main.py --server.port 10000 --server.address 0.0.0.0
```

---

## ğŸš€ Deployment on Render

1. Push this repo to GitHub
2. Go to [https://render.com](https://render.com)
3. Click "New â†’ Web Service"
4. Use:

   * Build Command: `pip install -r requirements.txt`
   * Start Command: `streamlit run main.py --server.port 10000 --server.address 0.0.0.0`
5. Wait for deployment and open your URL

---

## âœ… Bonus Features Implemented

* ğŸ§µ GPT-style Memory Handling
* ğŸ§  Follow-up questions answered using last 20 turns stored in memory.json
* ğŸ” Answer Highlighting: displays document snippet supporting each answer

---

## ğŸ“½ï¸ Optional: Demo Video (You can add later)

```
ğŸ¥ Demo: https://your-demo-link.com
```

---

## ğŸ“¬ Contact

Developed by Rimi Majumdar as part of the GenAI Internship Task.
